{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "e2e9a40f-f3ff-4707-9cff-ed01a1e49094",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "SYSTEM CHECK\n",
      "======================================================================\n",
      "ML:      ✅\n",
      "Viz:     ✅\n",
      "Llama:   ✅\n",
      "RAG:     ✅\n",
      "======================================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import json\n",
    "import time\n",
    "import warnings\n",
    "from pathlib import Path\n",
    "from datetime import datetime, timedelta\n",
    "from typing import Dict, List, Optional, Any\n",
    "from dataclasses import dataclass\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# ML\n",
    "try:\n",
    "    from prophet import Prophet\n",
    "    from sklearn.metrics import mean_absolute_percentage_error, mean_squared_error\n",
    "    ML_OK = True\n",
    "except:\n",
    "    ML_OK = False\n",
    "    print(\"⚠️  Install: pip install prophet scikit-learn\")\n",
    "\n",
    "# Visualization\n",
    "try:\n",
    "    import plotly.graph_objects as go\n",
    "    VIZ_OK = True\n",
    "except:\n",
    "    VIZ_OK = False\n",
    "    print(\"⚠️  Install: pip install plotly\")\n",
    "\n",
    "# Llama\n",
    "LLAMA_OK = False\n",
    "try:\n",
    "    from langchain_community.llms import Ollama\n",
    "    from langchain.callbacks.base import BaseCallbackHandler\n",
    "    from langchain.schema import Document\n",
    "    LLAMA_OK = True\n",
    "except:\n",
    "    print(\"⚠️  Llama packages missing (fallback mode)\")\n",
    "\n",
    "# RAG\n",
    "RAG_OK = False\n",
    "try:\n",
    "    from langchain_community.embeddings import HuggingFaceEmbeddings\n",
    "    from langchain_community.vectorstores import Chroma\n",
    "    RAG_OK = True\n",
    "except:\n",
    "    print(\"⚠️  RAG packages missing\")\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "np.random.seed(42)\n",
    "\n",
    "print(f\"\\n{'='*70}\")\n",
    "print(\"SYSTEM CHECK\")\n",
    "print(f\"{'='*70}\")\n",
    "print(f\"ML:      {'✅' if ML_OK else '❌'}\")\n",
    "print(f\"Viz:     {'✅' if VIZ_OK else '❌'}\")\n",
    "print(f\"Llama:   {'✅' if LLAMA_OK else '❌'}\")\n",
    "print(f\"RAG:     {'✅' if RAG_OK else '❌'}\")\n",
    "print(f\"{'='*70}\\n\")\n",
    "\n",
    "if not ML_OK:\n",
    "    raise ImportError(\"CRITICAL: Install prophet and scikit-learn\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "7ef91760-a1a4-4fcf-934e-0b0a075cc739",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Config loaded\n",
      "\n"
     ]
    }
   ],
   "source": [
    "@dataclass\n",
    "class Config:\n",
    "    forecast_days: int = 90\n",
    "    safety_stock: float = 1.1\n",
    "    target_mape: float = 10.0\n",
    "    lcs_forecast_w: float = 0.4\n",
    "    lcs_payment_w: float = 0.3\n",
    "    lcs_turnover_w: float = 0.3\n",
    "    lcs_threshold: int = 80\n",
    "    base_fee: float = 0.03\n",
    "    fee_factor: float = 0.0005\n",
    "    llama_model: str = \"llama3.2\"\n",
    "    llama_url: str = \"http://localhost:11434\"\n",
    "    llama_temp: float = 0.05\n",
    "    llama_tokens: int = 800\n",
    "    embed_model: str = \"all-MiniLM-L6-v2\"\n",
    "    chunk_size: int = 400\n",
    "    top_k: int = 3\n",
    "    data_dir: str = \"./sherpai_data\"\n",
    "    vector_dir: str = \"./sherpai_vectors\"\n",
    "    output_dir: str = \"./sherpai_output\"\n",
    "    \n",
    "    def __post_init__(self):\n",
    "        for d in [self.data_dir, self.vector_dir, self.output_dir]:\n",
    "            Path(d).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "CFG = Config()\n",
    "print(f\"✅ Config loaded\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "c587bfab-ac59-4f03-870d-097bbc3d93f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Stream handler ready\n",
      "\n"
     ]
    }
   ],
   "source": [
    "class StreamHandler(BaseCallbackHandler):\n",
    "    def __init__(self):\n",
    "        self.text = \"\"\n",
    "        self.tokens = 0\n",
    "        self.start = None\n",
    "    \n",
    "    def on_llm_start(self, *args, **kwargs):\n",
    "        self.start = time.time()\n",
    "        print(\"🧠 \", end=\"\", flush=True)\n",
    "    \n",
    "    def on_llm_new_token(self, token: str, **kwargs):\n",
    "        print(token, end=\"\", flush=True)\n",
    "        self.text += token\n",
    "        self.tokens += 1\n",
    "    \n",
    "    def on_llm_end(self, *args, **kwargs):\n",
    "        elapsed = time.time() - self.start if self.start else 0\n",
    "        print(f\"\\n\\n[{self.tokens} tokens, {elapsed:.1f}s]\")\n",
    "\n",
    "print(\"✅ Stream handler ready\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "6d918651-d2ae-4b5e-ba43-643a45376cbf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "INITIALIZING LLAMA\n",
      "======================================================================\n",
      "\n",
      "[1/3] Connecting...\n",
      "      ✅ Connected\n",
      "\n",
      "[2/3] Testing...\n",
      "      ✅ Working\n",
      "\n",
      "[3/3] Loading embeddings...\n",
      "      ⚠️  RAG disabled: Your currently installed version of Keras is Keras 3, but this is not yet supported in Transformers. Please install the backwards-compatible tf-keras package with `pip install tf-keras`.\n",
      "\n",
      "======================================================================\n",
      "✅ LLAMA OPERATIONAL\n",
      "======================================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "class LlamaEngine:\n",
    "    def __init__(self, cfg: Config):\n",
    "        self.cfg = cfg\n",
    "        self.llm = None\n",
    "        self.embeddings = None\n",
    "        self.vectorstore = None\n",
    "        self.ready = False\n",
    "    \n",
    "    def initialize(self) -> bool:\n",
    "        if not LLAMA_OK:\n",
    "            print(\"⚠️  Llama unavailable - using fallback\\n\")\n",
    "            return False\n",
    "        \n",
    "        print(f\"\\n{'='*70}\")\n",
    "        print(\"INITIALIZING LLAMA\")\n",
    "        print(f\"{'='*70}\\n\")\n",
    "        \n",
    "        try:\n",
    "            print(\"[1/3] Connecting...\")\n",
    "            self.llm = Ollama(\n",
    "                base_url=self.cfg.llama_url,\n",
    "                model=self.cfg.llama_model,\n",
    "                temperature=self.cfg.llama_temp,\n",
    "                num_predict=self.cfg.llama_tokens\n",
    "            )\n",
    "            print(f\"      ✅ Connected\\n\")\n",
    "        except Exception as e:\n",
    "            print(f\"      ❌ Failed: {e}\\n\")\n",
    "            return False\n",
    "        \n",
    "        try:\n",
    "            print(\"[2/3] Testing...\")\n",
    "            resp = self.llm.invoke(\"Say: OK\")\n",
    "            if resp and len(resp.strip()) > 0:\n",
    "                print(f\"      ✅ Working\\n\")\n",
    "            else:\n",
    "                print(f\"      ❌ Empty response\\n\")\n",
    "                return False\n",
    "        except Exception as e:\n",
    "            print(f\"      ❌ Test failed: {e}\\n\")\n",
    "            return False\n",
    "        \n",
    "        if RAG_OK:\n",
    "            try:\n",
    "                print(\"[3/3] Loading embeddings...\")\n",
    "                self.embeddings = HuggingFaceEmbeddings(\n",
    "                    model_name=self.cfg.embed_model,\n",
    "                    model_kwargs={'device': 'cpu'}\n",
    "                )\n",
    "                print(f\"      ✅ Ready\\n\")\n",
    "            except Exception as e:\n",
    "                print(f\"      ⚠️  RAG disabled: {e}\\n\")\n",
    "        \n",
    "        self.ready = True\n",
    "        print(f\"{'='*70}\")\n",
    "        print(\"✅ LLAMA OPERATIONAL\")\n",
    "        print(f\"{'='*70}\\n\")\n",
    "        return True\n",
    "    \n",
    "    def create_vectorstore(self, docs: List[Document]) -> bool:\n",
    "        if not self.embeddings:\n",
    "            return False\n",
    "        try:\n",
    "            print(f\"📚 Creating vectorstore...\")\n",
    "            self.vectorstore = Chroma.from_documents(\n",
    "                documents=docs,\n",
    "                embedding=self.embeddings,\n",
    "                persist_directory=self.cfg.vector_dir\n",
    "            )\n",
    "            self.vectorstore.persist()\n",
    "            print(f\"   ✅ Done\\n\")\n",
    "            return True\n",
    "        except:\n",
    "            return False\n",
    "    \n",
    "    def analyze(self, forecast: Dict, lcs: Dict, finance: Dict, \n",
    "                suppliers: List[Dict]) -> str:\n",
    "        if not self.ready:\n",
    "            return self._fallback(forecast, lcs, finance, suppliers)\n",
    "        \n",
    "        try:\n",
    "            ctx = self._make_context(forecast, lcs, finance, suppliers)\n",
    "            prompt = self._build_prompt(ctx)\n",
    "            \n",
    "            print(\"\\n🧭 sherpAI analyzing...\\n\")\n",
    "            handler = StreamHandler()\n",
    "            self.llm.invoke(prompt, callbacks=[handler])\n",
    "            \n",
    "            return f\"\"\"\n",
    "╔══════════════════════════════════════════════════════════════════════╗\n",
    "║                   🧭 SHERPAI RECOMMENDATION                          ║\n",
    "╚══════════════════════════════════════════════════════════════════════╝\n",
    "\n",
    "{handler.text}\n",
    "\n",
    "━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\n",
    "Powered by {self.cfg.llama_model}\n",
    "\"\"\"\n",
    "        except Exception as e:\n",
    "            print(f\"⚠️  AI failed: {e}\")\n",
    "            return self._fallback(forecast, lcs, finance, suppliers)\n",
    "    \n",
    "    def _make_context(self, f: Dict, l: Dict, fin: Dict, s: List[Dict]) -> str:\n",
    "        best = min(s, key=lambda x: x['price'])\n",
    "        return f\"\"\"FORECAST: {f['optimal_quantity']:,} units (expected {f['expected_demand']:,})\n",
    "LCS: {l['lcs_score']}/100 ({l['risk_category']})\n",
    "FINANCE: {fin['status']}\n",
    "SUPPLIER: {best['name']} @ ${best['price']:.2f}/unit\"\"\"\n",
    "    \n",
    "    def _build_prompt(self, ctx: str) -> str:\n",
    "        sys = \"You are sherpAI. Analyze and provide: 1) Forecast confidence 2) Order recommendation 3) Financing advice 4) Risks 5) Action steps. Be concise.\"\n",
    "        return f\"\"\"<|begin_of_text|><|start_header_id|>system<|end_header_id|>\n",
    "\n",
    "{sys}<|eot_id|><|start_header_id|>user<|end_header_id|>\n",
    "\n",
    "{ctx}\n",
    "\n",
    "Analyze.<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
    "\n",
    "\"\"\"\n",
    "    \n",
    "    def _fallback(self, f: Dict, l: Dict, fin: Dict, s: List[Dict]) -> str:\n",
    "        best = min(s, key=lambda x: x['price'])\n",
    "        return f\"\"\"\n",
    "╔══════════════════════════════════════════════════════════════════════╗\n",
    "║              📊 SHERPAI RECOMMENDATION (Fallback)                    ║\n",
    "╚══════════════════════════════════════════════════════════════════════╝\n",
    "\n",
    "⚠️  AI unavailable\n",
    "\n",
    "RECOMMENDATION:\n",
    "• Order: {f['optimal_quantity']:,} units\n",
    "• Supplier: {best['name']}\n",
    "• Expected: {f['expected_demand']:,} units\n",
    "• Risk: {f.get('stockout_risk', 'Unknown')}\n",
    "\n",
    "FINANCING:\n",
    "• Status: {fin['status']}\n",
    "• LCS: {l['lcs_score']}/100\n",
    "\"\"\"\n",
    "\n",
    "llama = LlamaEngine(CFG)\n",
    "LLAMA_READY = llama.initialize()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "f651da2c-f24f-4ae0-9749-9768d5d71f53",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Sales data: 1096 days\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def generate_sales(start: str, end: str) -> pd.DataFrame:\n",
    "    dates = pd.date_range(start, end, freq='D')\n",
    "    n = len(dates)\n",
    "    \n",
    "    trend = np.linspace(100, 150, n)\n",
    "    yearly = 30 * np.sin(2 * np.pi * np.arange(n) / 365.25)\n",
    "    weekly = 15 * np.sin(2 * np.pi * np.arange(n) / 7)\n",
    "    promos = np.zeros(n)\n",
    "    promo_idx = np.random.choice(n, int(n * 0.08), replace=False)\n",
    "    promos[promo_idx] = np.random.uniform(30, 70, len(promo_idx))\n",
    "    noise = np.random.normal(0, 10, n)\n",
    "    \n",
    "    sales = np.maximum(trend + yearly + weekly + promos + noise, 5)\n",
    "    \n",
    "    return pd.DataFrame({\n",
    "        'date': dates,\n",
    "        'sales': sales,\n",
    "        'revenue': sales * np.random.uniform(20, 30, n)\n",
    "    }).set_index('date')\n",
    "\n",
    "sales_data = generate_sales('2022-01-01', '2024-12-31')\n",
    "print(f\"✅ Sales data: {len(sales_data)} days\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "8312f6e4-04d5-48f8-a0e9-f18f114da375",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Forecast engine ready\n",
      "\n"
     ]
    }
   ],
   "source": [
    "class ForecastEngine:\n",
    "    def __init__(self, cfg: Config):\n",
    "        self.cfg = cfg\n",
    "        self.model = None\n",
    "        self.forecast = None\n",
    "        self.metrics = {}\n",
    "    \n",
    "    def train(self, df: pd.DataFrame) -> Dict:\n",
    "        print(\"\\n🔧 Training forecast...\")\n",
    "        \n",
    "        data = df.reset_index().rename(columns={'date': 'ds', 'sales': 'y'})\n",
    "        data['ds'] = pd.to_datetime(data['ds'])\n",
    "        \n",
    "        self.model = Prophet(\n",
    "            yearly_seasonality=True,\n",
    "            weekly_seasonality=True,\n",
    "            daily_seasonality=False,\n",
    "            changepoint_prior_scale=0.05,\n",
    "            interval_width=0.95\n",
    "        )\n",
    "        self.model.fit(data)\n",
    "        \n",
    "        pred = self.model.predict(data)\n",
    "        mape = mean_absolute_percentage_error(data['y'], pred['yhat']) * 100\n",
    "        rmse = np.sqrt(mean_squared_error(data['y'], pred['yhat']))\n",
    "        \n",
    "        self.metrics = {'mape': mape, 'rmse': rmse, 'samples': len(data)}\n",
    "        \n",
    "        print(f\"   {'✅ Excellent' if mape < self.cfg.target_mape else '✅ Good'}\")\n",
    "        print(f\"   MAPE: {mape:.2f}%, RMSE: {rmse:.2f}\\n\")\n",
    "        \n",
    "        return self.metrics\n",
    "    \n",
    "    def predict(self, days: int = None) -> pd.DataFrame:\n",
    "        days = days or self.cfg.forecast_days\n",
    "        future = self.model.make_future_dataframe(periods=days)\n",
    "        self.forecast = self.model.predict(future)\n",
    "        print(f\"✅ Forecast: {days} days\\n\")\n",
    "        return self.forecast\n",
    "    \n",
    "    def calc_order(self, stock: int = 0) -> Dict:\n",
    "        future = self.forecast[self.forecast['ds'] > datetime.now()].head(44)\n",
    "        exp = int(future['yhat'].sum())\n",
    "        opt = int(exp * self.cfg.safety_stock)\n",
    "        lo = max(0, int(future['yhat_lower'].sum()))\n",
    "        hi = int(future['yhat_upper'].sum())\n",
    "        \n",
    "        var = (hi - lo) / exp if exp > 0 else 0\n",
    "        risk = \"🟢 LOW\" if var < 0.2 else \"🟡 MED\" if var < 0.4 else \"🔴 HIGH\"\n",
    "        \n",
    "        return {\n",
    "            'optimal_quantity': opt,\n",
    "            'expected_demand': exp,\n",
    "            'current_stock': stock,\n",
    "            'lower_bound': lo,\n",
    "            'upper_bound': hi,\n",
    "            'forecast_period_days': len(future),\n",
    "            'stockout_risk': risk,\n",
    "            'safety_stock_units': opt - exp\n",
    "        }\n",
    "    \n",
    "    def visualize(self, df: pd.DataFrame) -> Optional[go.Figure]:\n",
    "        if not VIZ_OK:\n",
    "            print(\"⚠️  Plotly not available\")\n",
    "            return None\n",
    "        \n",
    "        fig = go.Figure()\n",
    "        \n",
    "        hist = df.reset_index()\n",
    "        fig.add_trace(go.Scatter(\n",
    "            x=hist['date'], y=hist['sales'],\n",
    "            mode='markers', name='Actual',\n",
    "            marker=dict(size=3, color='blue', opacity=0.5)\n",
    "        ))\n",
    "        \n",
    "        fut = self.forecast[self.forecast['ds'] > datetime.now()]\n",
    "        fig.add_trace(go.Scatter(\n",
    "            x=fut['ds'], y=fut['yhat'],\n",
    "            mode='lines', name='Forecast',\n",
    "            line=dict(color='red', width=2)\n",
    "        ))\n",
    "        \n",
    "        fig.add_trace(go.Scatter(\n",
    "            x=fut['ds'], y=fut['yhat_upper'],\n",
    "            mode='lines', line=dict(width=0),\n",
    "            showlegend=False\n",
    "        ))\n",
    "        \n",
    "        fig.add_trace(go.Scatter(\n",
    "            x=fut['ds'], y=fut['yhat_lower'],\n",
    "            mode='lines', line=dict(width=0),\n",
    "            fill='tonexty', fillcolor='rgba(255,0,0,0.2)',\n",
    "            name='95% CI'\n",
    "        ))\n",
    "        \n",
    "        # 🐛 FIX APPLIED: Separate line and annotation logic to avoid Plotly's internal TypeError.\n",
    "        today_iso = datetime.now().strftime('%Y-%m-%d')\n",
    "        \n",
    "        # 1. Add the vertical line using add_shape\n",
    "        fig.add_shape(\n",
    "            type=\"line\",\n",
    "            x0=today_iso, x1=today_iso, \n",
    "            y0=0, y1=1,\n",
    "            yref=\"paper\", # Use paper coordinates for Y to span the entire plot area\n",
    "            line=dict(dash=\"dash\", color=\"gray\", width=1)\n",
    "        )\n",
    "\n",
    "        # 2. Add the annotation (text) separately using add_annotation\n",
    "        fig.add_annotation(\n",
    "            text=\"Today\",\n",
    "            x=today_iso, \n",
    "            y=1.02, # Position text slightly above the top edge (y=1.0)\n",
    "            yref=\"paper\",\n",
    "            showarrow=False,\n",
    "            font=dict(color=\"gray\"),\n",
    "            xanchor=\"center\"\n",
    "        )\n",
    "        # -------------------------------------------------------------------------\n",
    "\n",
    "        fig.update_layout(\n",
    "            title=\"📈 sherpAI Forecast\",\n",
    "            xaxis_title=\"Date\",\n",
    "            yaxis_title=\"Sales\",\n",
    "            height=500,\n",
    "            template='plotly_white'\n",
    "        )\n",
    "        \n",
    "        return fig\n",
    "\n",
    "print(\"✅ Forecast engine ready\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "ab57327b-49e4-47cb-9118-796dbee70fd5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ LCS & Finance engines ready\n",
      "\n"
     ]
    }
   ],
   "source": [
    "class LCSEngine:\n",
    "    def __init__(self, cfg: Config):\n",
    "        self.cfg = cfg\n",
    "    \n",
    "    def calculate(self, mape: float, payment: List[bool] = None, \n",
    "                 turnover: float = None) -> Dict:\n",
    "        fs = max(0, 100 - (mape * 2))\n",
    "        if mape < 5:\n",
    "            fs = min(100, fs + (5 - mape) * 2)\n",
    "        \n",
    "        ps = (sum(payment) / len(payment) * 100) if payment else 60.0\n",
    "        \n",
    "        if turnover:\n",
    "            if 6 <= turnover <= 12:\n",
    "                ts = 100.0\n",
    "            elif turnover < 6:\n",
    "                ts = max(0, 100 - (6 - turnover) * 15)\n",
    "            else:\n",
    "                ts = max(0, 100 - (turnover - 12) * 8)\n",
    "        else:\n",
    "            ts = 50.0\n",
    "        \n",
    "        lcs = int(\n",
    "            fs * self.cfg.lcs_forecast_w +\n",
    "            ps * self.cfg.lcs_payment_w +\n",
    "            ts * self.cfg.lcs_turnover_w\n",
    "        )\n",
    "        \n",
    "        if lcs >= 90:\n",
    "            risk = \"Excellent (Very Low Risk)\"\n",
    "        elif lcs >= 80:\n",
    "            risk = \"Good (Low Risk)\"\n",
    "        elif lcs >= 70:\n",
    "            risk = \"Fair (Medium Risk)\"\n",
    "        elif lcs >= 60:\n",
    "            risk = \"Marginal (Med-High Risk)\"\n",
    "        else:\n",
    "            risk = \"Poor (High Risk)\"\n",
    "        \n",
    "        return {\n",
    "            'lcs_score': lcs,\n",
    "            'forecast_accuracy_score': int(fs),\n",
    "            'historical_performance_score': int(ps),\n",
    "            'inventory_turnover_score': int(ts),\n",
    "            'risk_category': risk,\n",
    "            'meets_threshold': lcs >= self.cfg.lcs_threshold\n",
    "        }\n",
    "\n",
    "class FinanceEngine:\n",
    "    def __init__(self, cfg: Config):\n",
    "        self.cfg = cfg\n",
    "    \n",
    "    def calculate(self, po_val: float, lcs: int) -> Dict:\n",
    "        if lcs < self.cfg.lcs_threshold:\n",
    "            return {\n",
    "                'status': 'REJECTED',\n",
    "                'reason': f'LCS {lcs} < {self.cfg.lcs_threshold}',\n",
    "                'principal': 0\n",
    "            }\n",
    "        \n",
    "        term = 60 if lcs >= 90 else 30\n",
    "        rate = self.cfg.base_fee + (100 - lcs) * self.cfg.fee_factor\n",
    "        fee = po_val * rate\n",
    "        total = po_val + fee\n",
    "        \n",
    "        return {\n",
    "            'status': 'APPROVED',\n",
    "            'principal': po_val,\n",
    "            'fee_rate': f'{rate * 100:.2f}%',\n",
    "            'fee_amount': fee,\n",
    "            'total_repayment': total,\n",
    "            'term_days': term,\n",
    "            'apr_equivalent': f'{(rate * 365 / term) * 100:.1f}%',\n",
    "            'lcs_score': lcs\n",
    "        }\n",
    "\n",
    "lcs_engine = LCSEngine(CFG)\n",
    "finance_engine = FinanceEngine(CFG)\n",
    "print(\"✅ LCS & Finance ready\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "4c6dc564-a550-4ed8-9479-864e58558754",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Suppliers ready\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def get_suppliers() -> List[Dict]:\n",
    "    return [\n",
    "        {'id': 'SUP_001', 'name': 'Primary Supplier Co.', \n",
    "         'price': 25.00, 'moq': 100, 'lead_days': 14, 'reliability': 95},\n",
    "        {'id': 'SUP_002', 'name': 'Backup Supplier Ltd.', \n",
    "         'price': 27.00, 'moq': 50, 'lead_days': 10, 'reliability': 88},\n",
    "        {'id': 'SUP_003', 'name': 'Economy Supplier Inc.', \n",
    "         'price': 23.50, 'moq': 200, 'lead_days': 21, 'reliability': 82}\n",
    "    ]\n",
    "\n",
    "def select_supplier(suppliers: List[Dict], qty: int) -> Dict:\n",
    "    valid = [s for s in suppliers if qty >= s['moq']]\n",
    "    if not valid:\n",
    "        return min(suppliers, key=lambda x: x['moq'])\n",
    "    return min(valid, key=lambda s: (s['price'] * qty) / (s['reliability'] / 100))\n",
    "\n",
    "print(\"✅ Suppliers ready\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "6f3a4763-8e20-46c7-b090-81ca48c0c38b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ RAG docs ready\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def prepare_docs(forecast_df: pd.DataFrame, metrics: Dict) -> List[Document]:\n",
    "    \"\"\"Convert forecast to documents\"\"\"\n",
    "    \n",
    "    docs = []\n",
    "    future = forecast_df[forecast_df['ds'] > datetime.now()]\n",
    "    \n",
    "    # Summary\n",
    "    summary = f\"\"\"Forecast: {future['yhat'].sum():.0f} units over {len(future)} days\n",
    "Avg daily: {future['yhat'].mean():.1f} units\n",
    "MAPE: {metrics['mape']:.2f}%\n",
    "Training: {metrics['samples']} samples\"\"\"\n",
    "    \n",
    "    docs.append(Document(page_content=summary))\n",
    "    \n",
    "    # Weekly\n",
    "    future_copy = future.copy()\n",
    "    future_copy['week'] = pd.to_datetime(future_copy['ds']).dt.isocalendar().week\n",
    "    weekly = future_copy.groupby('week').agg({\n",
    "        'yhat': 'sum',\n",
    "        'yhat_lower': 'sum',\n",
    "        'yhat_upper': 'sum'\n",
    "    }).reset_index()\n",
    "    \n",
    "    for _, row in weekly.head(6).iterrows():\n",
    "        week_text = f\"Week {int(row['week'])}: {row['yhat']:.0f} units expected\"\n",
    "        docs.append(Document(page_content=week_text))\n",
    "    \n",
    "    # Risk\n",
    "    var = (future['yhat_upper'] - future['yhat_lower']).mean() / future['yhat'].mean()\n",
    "    risk_text = f\"Variability: {var:.1%}\"\n",
    "    docs.append(Document(page_content=risk_text))\n",
    "    \n",
    "    return docs\n",
    "\n",
    "print(\"✅ RAG docs ready\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "ff2735d2-4770-4e61-a522-cef4d600c9a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ SherpAI system ready\n",
      "\n"
     ]
    }
   ],
   "source": [
    "class SherpAI:\n",
    "    def __init__(self, cfg: Config, llama_engine: LlamaEngine):\n",
    "        self.cfg = cfg\n",
    "        self.llama = llama_engine\n",
    "        self.forecast = ForecastEngine(cfg)\n",
    "        self.lcs = lcs_engine\n",
    "        self.finance = finance_engine\n",
    "    \n",
    "    def analyze(self, sales_df: pd.DataFrame, stock: int = 50) -> Dict:\n",
    "        print(f\"\\n{'='*70}\")\n",
    "        print(\"🧭 SHERPAI ANALYSIS\")\n",
    "        print(f\"{'='*70}\\n\")\n",
    "        \n",
    "        # Train\n",
    "        print(\"[1/7] Training...\")\n",
    "        metrics = self.forecast.train(sales_df)\n",
    "        \n",
    "        # Forecast\n",
    "        print(\"[2/7] Forecasting...\")\n",
    "        forecast_df = self.forecast.predict()\n",
    "        \n",
    "        # Order\n",
    "        print(\"[3/7] Calculating order...\")\n",
    "        order = self.forecast.calc_order(stock)\n",
    "        print(f\"      Optimal: {order['optimal_quantity']:,} units\\n\")\n",
    "        \n",
    "        # Suppliers\n",
    "        print(\"[4/7] Evaluating suppliers...\")\n",
    "        suppliers = get_suppliers()\n",
    "        best = select_supplier(suppliers, order['optimal_quantity'])\n",
    "        print(f\"      Best: {best['name']}\\n\")\n",
    "        \n",
    "        # LCS\n",
    "        print(\"[5/7] Calculating LCS...\")\n",
    "        lcs_data = self.lcs.calculate(metrics['mape'], [True]*10, 8.5)\n",
    "        print(f\"      LCS: {lcs_data['lcs_score']}/100\\n\")\n",
    "        \n",
    "        # Finance\n",
    "        print(\"[6/7] Calculating financing...\")\n",
    "        po_val = order['optimal_quantity'] * best['price']\n",
    "        financing = self.finance.calculate(po_val, lcs_data['lcs_score'])\n",
    "        print(f\"      Status: {financing['status']}\\n\")\n",
    "        \n",
    "        # RAG\n",
    "        if self.llama.ready and self.llama.embeddings:\n",
    "            print(\"[7/7] Indexing for RAG...\")\n",
    "            docs = prepare_docs(forecast_df, metrics)\n",
    "            self.llama.create_vectorstore(docs)\n",
    "        \n",
    "        # AI recommendation\n",
    "        print(\"[7/7] Generating recommendation...\")\n",
    "        recommendation = self.llama.analyze(order, lcs_data, financing, suppliers)\n",
    "        \n",
    "        print(f\"\\n{'='*70}\")\n",
    "        print(\"✅ COMPLETE\")\n",
    "        print(f\"{'='*70}\\n\")\n",
    "        \n",
    "        return {\n",
    "            'sales_data': sales_df,\n",
    "            'forecast_metrics': metrics,\n",
    "            'forecast': forecast_df,\n",
    "            'order_data': order,\n",
    "            'suppliers': suppliers,\n",
    "            'best_supplier': best,\n",
    "            'lcs_data': lcs_data,\n",
    "            'financing': financing,\n",
    "            'recommendation': recommendation,\n",
    "            'po_value': po_val\n",
    "        }\n",
    "    \n",
    "    def visualize(self, results: Dict):\n",
    "        return self.forecast.visualize(results['sales_data'])\n",
    "\n",
    "sherp = SherpAI(CFG, llama)\n",
    "print(\"✅ SherpAI system ready\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "df6d2dd2-62dc-4886-9159-659946c1f0c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Main execution ready\n",
      "\n",
      "======================================================================\n",
      "✅ SHERPAI FULLY LOADED\n",
      "======================================================================\n",
      "\n",
      "STATUS:\n",
      "  ML/Forecasting:    ✅\n",
      "  Visualization:     ✅\n",
      "  Llama Engine:      ✅\n",
      "  RAG System:        ⚠️  Disabled\n",
      "  Data Generated:    ✅ 1096 days\n",
      "\n",
      "======================================================================\n",
      "🎉 SHERPAI READY\n",
      "======================================================================\n",
      "\n",
      "🚀 TO RUN:\n",
      ">>> results, chart = run_sherpai()\n",
      ">>> chart.show()\n",
      "======================================================================\n",
      "\n",
      "✅ Ready! Execute run_sherpai() to start.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def run_sherpai():\n",
    "    \"\"\"Execute complete analysis\"\"\"\n",
    "    \n",
    "    print(\"\"\"\n",
    "╔══════════════════════════════════════════════════════════════════════╗\n",
    "║                        🧭 sherpAI v1.0                               ║\n",
    "╚══════════════════════════════════════════════════════════════════════╝\n",
    "    \"\"\")\n",
    "    \n",
    "    results = sherp.analyze(sales_data, stock=75)\n",
    "    \n",
    "    print(results['recommendation'])\n",
    "    \n",
    "    print(\"\\n📊 Generating visualization...\")\n",
    "    chart = sherp.visualize(results)\n",
    "    \n",
    "    print(f\"\\n{'='*70}\")\n",
    "    print(\"📈 KEY METRICS\")\n",
    "    print(f\"{'='*70}\")\n",
    "    print(f\"Forecast MAPE:        {results['forecast_metrics']['mape']:.2f}%\")\n",
    "    print(f\"LCS Score:            {results['lcs_data']['lcs_score']}/100\")\n",
    "    print(f\"Risk Category:        {results['lcs_data']['risk_category']}\")\n",
    "    print(f\"Optimal Order:        {results['order_data']['optimal_quantity']:,} units\")\n",
    "    print(f\"Expected Demand:      {results['order_data']['expected_demand']:,} units\")\n",
    "    print(f\"PO Value:             ${results['po_value']:,.2f}\")\n",
    "    print(f\"Financing Status:     {results['financing']['status']}\")\n",
    "    print(f\"Best Supplier:        {results['best_supplier']['name']}\")\n",
    "    print(f\"Stockout Risk:        {results['order_data']['stockout_risk']}\")\n",
    "    print(f\"{'='*70}\")\n",
    "    \n",
    "    print(\"\\n💡 NEXT STEPS:\")\n",
    "    print(f\"{'='*70}\")\n",
    "    if chart:\n",
    "        print(\"1. View chart:        chart.show()\")\n",
    "    print(\"2. Export results:    export_results(results)\")\n",
    "    print(\"3. Access data:       results['forecast'].tail(30)\")\n",
    "    print(f\"{'='*70}\\n\")\n",
    "    \n",
    "    return results, chart\n",
    "\n",
    "def export_results(results: Dict, dir: str = None):\n",
    "    \"\"\"Export results to files\"\"\"\n",
    "    \n",
    "    output_dir = dir or CFG.output_dir\n",
    "    Path(output_dir).mkdir(exist_ok=True)\n",
    "    \n",
    "    results['forecast'].to_csv(f\"{output_dir}/forecast.csv\", index=False)\n",
    "    \n",
    "    with open(f\"{output_dir}/recommendation.txt\", 'w') as f:\n",
    "        f.write(results['recommendation'])\n",
    "    \n",
    "    summary = {\n",
    "        'timestamp': datetime.now().isoformat(),\n",
    "        'forecast_mape': results['forecast_metrics']['mape'],\n",
    "        'lcs_score': results['lcs_data']['lcs_score'],\n",
    "        'risk_category': results['lcs_data']['risk_category'],\n",
    "        'optimal_quantity': results['order_data']['optimal_quantity'],\n",
    "        'expected_demand': results['order_data']['expected_demand'],\n",
    "        'po_value': results['po_value'],\n",
    "        'financing_status': results['financing']['status'],\n",
    "        'best_supplier': results['best_supplier']['name'],\n",
    "        'stockout_risk': results['order_data']['stockout_risk']\n",
    "    }\n",
    "    \n",
    "    with open(f\"{output_dir}/summary.json\", 'w') as f:\n",
    "        json.dump(summary, f, indent=2)\n",
    "    \n",
    "    print(f\"\\n✅ Results exported to: {output_dir}/\")\n",
    "    print(\"   • forecast.csv\")\n",
    "    print(\"   • recommendation.txt\")\n",
    "    print(\"   • summary.json\\n\")\n",
    "\n",
    "print(\"✅ Main execution ready\\n\")\n",
    "\n",
    "# ═══════════════════════════════════════════════════════════════════════\n",
    "# FINAL STATUS\n",
    "# ═══════════════════════════════════════════════════════════════════════\n",
    "\n",
    "print(f\"{'='*70}\")\n",
    "print(\"✅ SHERPAI FULLY LOADED\")\n",
    "print(f\"{'='*70}\")\n",
    "print(\"\\nSTATUS:\")\n",
    "print(f\"  ML/Forecasting:    {'✅' if ML_OK else '❌'}\")\n",
    "print(f\"  Visualization:     {'✅' if VIZ_OK else '❌'}\")\n",
    "print(f\"  Llama Engine:      {'✅' if LLAMA_READY else '⚠️  Fallback'}\")\n",
    "print(f\"  RAG System:        {'✅' if RAG_OK and llama.embeddings else '⚠️  Disabled'}\")\n",
    "print(f\"  Data Generated:    ✅ {len(sales_data)} days\")\n",
    "\n",
    "print(f\"\\n{'='*70}\")\n",
    "\n",
    "if LLAMA_READY:\n",
    "    print(\"🎉 SHERPAI READY\")\n",
    "    print(f\"{'='*70}\")\n",
    "    print(\"\\n🚀 TO RUN:\")\n",
    "    print(\">>> results, chart = run_sherpai()\")\n",
    "    if VIZ_OK:\n",
    "        print(\">>> chart.show()\")\n",
    "else:\n",
    "    print(\"⚠️  Running in fallback mode\")\n",
    "    print(f\"{'='*70}\")\n",
    "    print(\"\\n🚀 TO RUN:\")\n",
    "    print(\">>> results, chart = run_sherpai()\")\n",
    "\n",
    "print(f\"{'='*70}\")\n",
    "print(\"\\n✅ Ready! Execute run_sherpai() to start.\\n\") "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
